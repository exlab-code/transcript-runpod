#!/bin/bash

echo "ğŸ³ RunPod Docker Local Testing Script"
echo "====================================="

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker Desktop first."
    exit 1
fi

echo "âœ… Docker is running"

# Build the image
echo ""
echo "ğŸ”¨ Building Docker image..."
docker build -t transcript-runpod-test . || {
    echo "âŒ Docker build failed"
    exit 1
}

echo "âœ… Docker image built successfully"

# Detect if we're on Mac (no NVIDIA GPU support)
if [[ "$OSTYPE" == "darwin"* ]]; then
    echo "ğŸ Detected macOS - GPU testing not available locally"
    echo "ğŸ“ Will test CPU mode and Docker environment setup"
    GPU_AVAILABLE=false
else
    echo "ğŸ§ Linux detected - testing GPU support"
    GPU_AVAILABLE=true
fi

# Test Docker environment setup
echo ""
echo "ğŸ§ª Testing Docker environment and dependencies..."

if $GPU_AVAILABLE; then
    echo "Running GPU test: docker run --gpus all..."
    if docker run --gpus all --rm -v "$(pwd)/test_input.json:/test_input.json" transcript-runpod-test python3 rp_handler.py --test_input /test_input.json; then
        echo "âœ… GPU test successful! cuDNN issue is fixed!"
        exit 0
    else
        echo "âŒ GPU test failed - checking details..."
    fi
fi

# Test CPU mode and environment
echo ""
echo "ğŸ”„ Testing CPU mode and Docker environment..."
if docker run --rm -v "$(pwd)/test_input.json:/test_input.json" transcript-runpod-test python3 -c "
import sys
print(f'Python version: {sys.version}')

try:
    import torch
    print(f'âœ… PyTorch: {torch.__version__}')
    print(f'CUDA available in container: {torch.cuda.is_available()}')
except Exception as e:
    print(f'âŒ PyTorch issue: {e}')

try:
    from faster_whisper import WhisperModel
    print('âœ… faster-whisper imported successfully')
    
    # Test CPU model creation
    print('ğŸ§ª Testing CPU model creation...')
    model = WhisperModel('tiny', device='cpu', compute_type='int8')
    print('âœ… CPU Whisper model created successfully!')
    
except Exception as e:
    print(f'âŒ faster-whisper issue: {e}')

try:
    import runpod
    print('âœ… RunPod SDK imported successfully')
except Exception as e:
    print(f'âŒ RunPod SDK issue: {e}')

print('ğŸ¯ Docker environment test complete!')
"; then
    if $GPU_AVAILABLE; then
        echo "âœ… Docker environment OK, but GPU/cuDNN issue remains"
        echo "ğŸ” This confirms the cuDNN library problem exists"
    else
        echo "âœ… Docker environment working perfectly!"
        echo "ğŸš€ Ready to deploy to RunPod (cuDNN fix should work there)"
    fi
else
    echo "âŒ Docker environment has fundamental issues"
    exit 1
fi

echo ""
echo "ğŸš€ To test interactively:"
echo "docker run --gpus all -it --rm transcript-runpod-test bash"
echo ""
echo "ğŸ“ To test the local server:"
echo "docker run --gpus all -p 8080:8080 --rm transcript-runpod-test python3 rp_handler.py --rp_serve_api --rp_api_port 8080"
echo "Then: curl -X POST http://localhost:8080/run -H 'Content-Type: application/json' -d @test_input.json"